# Responsible AI

This folder contains examples related to responsible AI with Amazon Bedrock.

Key elements of responsible AI include:

- **Fairness**: How a system impacts different subpopulations of users (e.g. by gender, ethnicity)
- **Explainability**: Mechanisms to understand and evaluate the outputs of an AI system
- **Privacy and security**: Data protected from theft and exposure
- **Robustness**: Mechanisms to ensure an AI system operates reliably
- **Governance**: Processes to define, implement and enforce responsible AI practices within an organization
- **Transparency**: Communicating information about an AI system so stakeholders can make informed choices about their use of the system

More on responsible AI [here](https://aws.amazon.com/machine-learning/responsible-ai/) and [here](https://aws.amazon.com/blogs/machine-learning/announcing-new-tools-and-capabilities-to-enable-responsible-ai-innovation/).

## Contents

- [Guardrails](guardrails) - Implement safeguards customized to your application requirements and responsible AI policies

## Contributing

We welcome community contributions! Please ensure your sample aligns with AWS [best practices](https://aws.amazon.com/architecture/well-architected/), and please update the **Contents** section of this README file with a link to your sample, along with a description.
